{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Customer Churn Prediction\n",
    "\n",
    "A business-driven approach to predicting customer churn, optimizing for revenue impact rather than traditional ML metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Context\n",
    "\n",
    "### What is the business objective?\n",
    "\n",
    "The company wants to create a predictive model that identifies customers likely to churn *before* it happens, enabling proactive retention efforts.\n",
    "\n",
    "The model will run automatically on all customers at fixed intervals. Its output will feed into another ML system that generates personalized temporary discounts to motivate at-risk customers to stay.\n",
    "\n",
    "**Output format:** Easy to process (JSON, YAML, etc.) containing only the customer IDs with positive churn predictions.\n",
    "\n",
    "### What is the current solution?\n",
    "\n",
    "Currently, retention efforts are reactive. Only after a customer leaves does a dedicated employee contact them with a custom discount offer (significant discount as a last resort).\n",
    "\n",
    "- Win-back success rate: **15-30%**\n",
    "- That means **70-85% of customers who leave are lost permanently**\n",
    "- Average discount offered to churned customers: **20-40% off** standard rate\n",
    "\n",
    "### What do we expect from the model?\n",
    "\n",
    "- Save costly and time-consuming customer chasing\n",
    "- Preserve customers with smaller discounts (or none at all)\n",
    "- Shift from reactive to proactive retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import plot_threshold_analysis, calculate_value_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "og_df = kagglehub.dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"blastchar/telco-customer-churn\",\n",
    "    file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = og_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store customer IDs separately and remove from features\n",
    "customers = df[\"customerID\"]\n",
    "df = df.drop(\"customerID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "### Convert categorical values to numeric representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def object_to_int(col: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert object columns to integer using label encoding.\"\"\"\n",
    "    if col.dtype == 'object':\n",
    "        col = LabelEncoder().fit_transform(col)\n",
    "    return col\n",
    "\n",
    "df = df.apply(object_to_int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current churn rate: 27%\n",
    "\n",
    "1,869 customers that leave multiplied by $4,100.30 (net value per saved customer) equals **$7,663,460.70** in potential lost revenue.\n",
    "\n",
    "**Note:** The target variable is imbalanced. This needs to be considered in both train/test splits and performance measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Churn'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with zero tenure (data quality issue)\n",
    "df.drop(labels=df[df['tenure'] == 0].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Business Insights from Correlation Analysis\n",
    "\n",
    "1. **Lock customers in early:** Contract type matters most. Incentivize long-term contracts.\n",
    "2. **Critical first 6-12 months:** Low tenure predicts churn. Onboarding and early experience are crucial.\n",
    "3. **Add-on services work:** Tech support, security, and backup all reduce churn significantly. Bundle these!\n",
    "4. **Price sensitivity is real:** High monthly charges drive churn, but interestingly, total spending doesn't matter as much.\n",
    "5. **Target families:** Customers with partners/dependents are stickier.\n",
    "6. **Watch new customers closely:** High monthly charges + short tenure + month-to-month contract = high churn risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "### Creating a Composite Risk Feature\n",
    "\n",
    "Two features show strong correlation with churn:\n",
    "- **MonthlyCharges** (positive correlation): Higher charges increase churn risk\n",
    "- **Tenure** (negative correlation): Longer tenure decreases churn risk\n",
    "\n",
    "By dividing monthly charge by tenure, we get a \"risk measurement\":\n",
    "- High monthly charge + low tenure = **high risk value**\n",
    "\n",
    "```\n",
    "high_churn_risk = MonthlyCharges / tenure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"high_churn_risk\"] = df[\"MonthlyCharges\"] / df[\"tenure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the new feature improves correlation\n",
    "df.corr()['Churn'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `high_churn_risk` feature has the strongest positive correlation (0.39) with churn, validating our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-correlation features and the features used to create the composite\n",
    "low_corr_features = [\"PhoneService\", \"gender\", \"MultipleLines\"]\n",
    "used_features = [\"MonthlyCharges\", \"tenure\"]\n",
    "\n",
    "df = df.drop(low_corr_features + used_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Pipeline\n",
    "\n",
    "### Normalizing Numeric Values\n",
    "\n",
    "We transform numerical data so all features are on the same scale by adjusting values so the mean is 0 and standard deviation is 1.\n",
    "\n",
    "A pipeline is used to apply this transformation consistently during cross-validation, avoiding data leakage between train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_columns = [\"TotalCharges\"]\n",
    "\n",
    "scale_numeric_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), numeric_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessing', scale_numeric_transformer),\n",
    "    ('model', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "thresholds = [0.30, 0.40, 0.50, 0.60, 0.70]\n",
    "\n",
    "# Use stratified k-fold to handle class imbalance\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "churn_scores_rf = cross_val_predict(pipeline_rf, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "print(\"Sample churn probability scores:\", churn_scores_rf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fpr_rf = plot_threshold_analysis(y, churn_scores_rf, thresholds_to_mark=thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessing', scale_numeric_transformer),\n",
    "    ('model', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "churn_scores_lr = cross_val_predict(pipeline_lr, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "print(\"Sample churn probability scores:\", churn_scores_lr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fpr_lr = plot_threshold_analysis(y, churn_scores_lr, thresholds_to_mark=thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Value Optimization\n",
    "\n",
    "### Translating Threshold Choice to Revenue\n",
    "\n",
    "The average Customer Lifetime Value (CLV) is approximately **$4,400.30**, while the average retention discount cost for a high-risk customer is around **$300**.\n",
    "\n",
    "Net value per saved customer: $4,440 - $300 = **$4,100.30**\n",
    "\n",
    "The optimal threshold maximizes:\n",
    "```\n",
    "Value = (Recall x $4,100.30) - (FPR x $300)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLV = 4400.30\n",
    "discount = 300\n",
    "\n",
    "value_scores, optimal_threshold, optimal_idx = calculate_value_scores(\n",
    "    thresholds, \n",
    "    recall_fpr_lr, \n",
    "    clv=CLV, \n",
    "    discount=discount\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact calculation\n",
    "churners = 1869\n",
    "non_churners = 5174\n",
    "\n",
    "# Baseline: Cost of doing nothing (lose all churners)\n",
    "baseline_loss = churners * CLV\n",
    "print(f\"Baseline loss (27% churn, no intervention): ${baseline_loss:,.2f}\")\n",
    "\n",
    "# With model at optimal threshold (TH=0.30)\n",
    "recall_at_threshold = recall_fpr_lr['recall'][0]  # 0.30 threshold\n",
    "fpr_at_threshold = recall_fpr_lr['fpr'][0]\n",
    "\n",
    "true_positives = churners * recall_at_threshold\n",
    "false_positives = non_churners * fpr_at_threshold\n",
    "\n",
    "# Revenue impact\n",
    "saved_value = true_positives * (CLV - discount)\n",
    "wasted_discounts = false_positives * discount\n",
    "net_value = saved_value - wasted_discounts\n",
    "\n",
    "print(f\"\\nWith Model (TH=0.30):\")\n",
    "print(f\"  Churners identified: {true_positives:.0f} out of {churners} ({recall_at_threshold:.1%})\")\n",
    "print(f\"  Value from saved churners: ${saved_value:,.2f}\")\n",
    "print(f\"  Cost of false alarms: ${wasted_discounts:,.2f}\")\n",
    "print(f\"  Net value gained: ${net_value:,.2f}\")\n",
    "print(f\"\\nRemaining loss (missed churners): ${(churners - true_positives) * CLV:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "For the dataset with:\n",
    "- 1,869 churners\n",
    "- 5,174 non-churners\n",
    "- CLV = $4,400.30\n",
    "- Retention discount = $300\n",
    "\n",
    "### Results\n",
    "\n",
    "| Scenario | Value |\n",
    "|----------|-------|\n",
    "| Baseline (no model) | -$8,224,160.70 loss |\n",
    "| With model (TH=0.30) | +$5,393,108.69 saved |\n",
    "| Remaining loss | -$2,006,695.21 |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **The model saves approximately $5.4M** compared to doing nothing\n",
    "2. **75.6% of churners are correctly identified** at the optimal threshold\n",
    "3. **24.4% of churners are missed**, representing ~$2M in unavoidable loss\n",
    "4. **The cost of false positives is acceptable** ($300 discount vs. $4,400 CLV makes it worthwhile to over-predict slightly)\n",
    "\n",
    "### Business Recommendation\n",
    "\n",
    "Deploy the model with a **0.30 probability threshold**. The asymmetric cost structure (losing a customer costs 14x more than an unnecessary discount) justifies prioritizing recall over precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
